{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Names: 187\n",
      "Number of columns: 30\n",
      "Number of rows: 31257\n",
      "Name of columns: Index(['Name', 'Sad', 'Guilty', 'Happy', 'Hopeless', 'Anxious', 'Stressed',\n",
      "       'Overwhelmed', 'Angry', 'Calm', 'Energetic', 'Lonely', 'In pain',\n",
      "       'Dizzy', 'Nauseous', 'Racing Heart', 'Look forward completing tasks',\n",
      "       'Satisfied with myself', 'Satisfied with my physical appearance',\n",
      "       'Cravings', 'Crave_Food', 'Enjoying moment', 'With how many people',\n",
      "       'Eating', 'Eating_healthy', 'In control', 'Concentrated', 'Worried',\n",
      "       'WrongDoing', 'Impulsivity'],\n",
      "      dtype='object')\n",
      "Number of samples: 180\n",
      "Number of Names: 187\n",
      "Shape of np_samples: (180, 120, 30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "DF=pd.read_excel('../NSMD/PreProcessed/29var/df29.xlsx')\n",
    "DF['datetime']=DF['Date']+' '+DF['Time']\n",
    "DF['datetime']=pd.to_datetime(DF['datetime'])\n",
    "DF.set_index('datetime',inplace=True)\n",
    "DF.drop(['Date','Time','Duration'],axis=1,inplace=True)\n",
    "DF.sort_index(inplace=True)\n",
    "#\n",
    "\n",
    "print('Number of unique Names:',DF['Name'].nunique())\n",
    "print('Number of columns:',len(DF.columns))\n",
    "print('Number of rows:',len(DF))\n",
    "print('Name of columns:',DF.columns)\n",
    "\n",
    "lengths=[]\n",
    "samples=[]\n",
    "for k in DF.Name.unique().tolist():\n",
    "    lengths.append(len(DF[DF['Name']==k]))\n",
    "    if len(DF[DF['Name']==k])>=120:\n",
    "        temp=DF[DF['Name']==k]\n",
    "        samples.append(temp.iloc[:120,:])\n",
    "print('Number of samples:',len(samples))\n",
    "print('Number of Names:',len(DF.Name.unique().tolist()))\n",
    "\n",
    "samples=pd.concat(samples)\n",
    "np_samples=[]\n",
    "for k in samples.Name.unique().tolist():\n",
    "    np_samples.append(np.array(samples[samples['Name']==k]))\n",
    "np_samples=np.array(np_samples)\n",
    "print('Shape of np_samples:',np_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_univariate(data, target_feature_index, n_lags=5):\n",
    "    \"\"\"\n",
    "    Preprocess the data for univariate time series prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    data (numpy array): The original dataset of shape (samples, timesteps, features).\n",
    "    target_feature_index (int): The index of the target feature.\n",
    "    n_lags (int): The number of lagged observations to use for prediction.\n",
    "    \n",
    "    Returns:\n",
    "    X (numpy array): Input features of shape (samples, n_lags, features).\n",
    "    y (numpy array): Target values of shape (samples, 1).\n",
    "    \"\"\"\n",
    "    n_samples, n_timesteps, n_features = data.shape\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        for t in range(n_lags, n_timesteps):\n",
    "            X.append(data[sample, t-n_lags:t, target_feature_index])\n",
    "            y.append(data[sample, t, target_feature_index])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48216,     1,     1, ...,     2,     7,     1],\n",
       "       [48216,     1,     1, ...,     1,     7,     1],\n",
       "       [48216,     1,     1, ...,     1,     7,     1],\n",
       "       ...,\n",
       "       [48216,     1,     3, ...,     3,     7,     1],\n",
       "       [48216,     1,     1, ...,     1,     7,     1],\n",
       "       [48216,     1,     1, ...,     1,     7,     1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        ...,\n",
       "        [5, 4, 2, 5, 4],\n",
       "        [4, 2, 5, 4, 5],\n",
       "        [2, 5, 4, 5, 6]]),\n",
       " array([1, 1, 1, ..., 5, 6, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_univariate(np_samples,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
